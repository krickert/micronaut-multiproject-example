syntax = "proto3";

// Defines the core data structures used throughout the pipeline system.
package com.krickert.search.model;

// Java generation options
option java_multiple_files = true;
option java_package = "com.krickert.search.model";

// --- Standard Google Imports ---
import "google/protobuf/timestamp.proto"; // For timestamps
import "google/protobuf/struct.proto";     // For flexible JSON-like structures
import "google/protobuf/empty.proto";      // For empty responses (though not directly used here)

// =============================================================================
// Core Document Representation
// =============================================================================

// PipeDoc represents the primary data object being processed by the pipeline.
// It contains structured text, metadata, embeddings, and potentially custom data.
message PipeDoc {
  // Unique identifier for the document, typically a UUID. REQUIRED.
  string id = 1;
  // Document title.
  optional string title = 2;
  // Main textual content of the document.
  optional string body = 3;
  // List of keywords associated with the document.
  repeated string keywords = 4;
  // Type classifier for the document (e.g., "article", "product", "email").
  optional string document_type = 5;
  // Revision identifier, if applicable (e.g., version number, commit hash).
  optional string revision_id = 6;
  // Timestamp of the document's creation.
  optional google.protobuf.Timestamp creation_date = 7;
  // Timestamp of the last modification.
  optional google.protobuf.Timestamp last_modified = 8;
  // Flexible key-value store for custom metadata not fitting standard fields.
  // Can be used for source-specific attributes, temporary processing data, etc.
  optional google.protobuf.Struct custom_data = 9;
  // Holds semantic chunk information and their embeddings, typically generated
  // by chunking and embedding pipeline steps.
  optional SemanticDoc chunk_embeddings = 10;
  // Map for storing named embeddings, potentially for the whole document
  // or specific sections other than semantic chunks. Key could be model name.
  map<string, Embedding> embeddings = 11;
}

// Represents a single named vector embedding.
message Embedding {
  // The vector representation.
  repeated float embedding = 1;
}

// Represents the result of semantic chunking applied to a document field.
message SemanticDoc {
  // ID of the parent PipeDoc.
  string parent_id = 1;
  // Name of the field within the parent PipeDoc that was chunked (e.g., "body").
  string parent_field = 2;
  // Identifier for the chunking configuration used.
  string chunk_config_id = 3;
  // Identifier for the semantic embedding model/configuration used.
  string semantic_config_id = 4;
  // List of semantic chunks generated.
  repeated SemanticChunk chunks = 5;
}

// Represents a single semantic chunk of text with its embedding.
message SemanticChunk {
  // Unique identifier for this specific chunk.
  string chunk_id = 1;
  // Sequential number of the chunk within the parent field.
  int64 chunk_number = 2;
  // The embedding information for this chunk.
  ChunkEmbedding embedding = 3;
}

// Represents the text content and vector embedding for a chunk.
message ChunkEmbedding {
  // The actual text content of the chunk.
  string embedding_text = 1;
  // The vector embedding for this chunk's text.
  repeated float embedding = 2;
}

// =============================================================================
// Routing and Error Structures
// =============================================================================

// Defines a potential destination for routing within the pipeline configuration.
// Note: This is primarily for configuration definition and error reporting,
// as the engine handles actual routing based on config.
message Route {
  // The type of the destination.
  RouteType routeType = 1;
  // The address or identifier of the destination (e.g., Kafka topic, gRPC service name).
  string destination = 2;
}

// Enum defining the types of routing destinations.
enum RouteType {
  // Unknown or unspecified route type.
  UNKNOWN = 0;
  // Represents the end of a pipeline path.
  NULL_TERMINATION = 1;
  // Destination is an Apache Kafka topic.
  KAFKA = 2;
  // Destination is another gRPC service (typically a PipeStepProcessor).
  GRPC = 3;
}

// Represents the input state for a single pipeline step execution.
// Note: This is primarily used within ErrorData for debugging failed steps.
// The actual request to a PipeStepProcessor is defined separately.
message PipeRequest {
  // The document state *before* the step was attempted.
  PipeDoc doc = 1;
  // The configuration parameters used for the step attempt.
  map<string, string> config = 2;
}

// Structured information about an error that occurred during processing.
// Used in HistoryEntry and potentially propagated in responses.
message ErrorData {
  // DEPRECATED: Use google.protobuf.Struct in HistoryEntry for richer details.
  // string errorMessage = 1; [deprecated = true];

  // Human-readable description of the error.
  string error_message = 2;
  // The route(s) that were intended to be taken when the error occurred.
  // Useful for debugging routing failures.
  repeated Route failedRoutes = 3;
  // The state of the request just before the failed step was attempted.
  // Useful for reproducing the error.
  optional PipeRequest error_request_state = 4; // Renamed for clarity
  // Optional: Machine-readable error code (e.g., "CONFIG_ERROR", "TIMEOUT").
  optional string error_code = 5;
  // Optional: Snippet of stack trace or further technical details.
  optional string technical_details = 6;
}

// Represents the outcome of a single pipeline step execution attempt.
// Note: This is primarily used within the PipeStream's history.
// The actual response from a PipeStepProcessor is defined separately.
message PipeResponse {
  // Indicates if the step execution attempt was successful.
  bool success = 1;
  // Details of the error if success is false.
  optional ErrorData error_data = 2; // Renamed for clarity
}

// =============================================================================
// Binary Data Handling
// =============================================================================

// Represents a block of binary data, potentially with associated metadata.
// Used for initial input or intermediate binary results within a PipeStream.
message Blob {
  // The raw binary content. REQUIRED.
  bytes blob = 1;
  // Optional: MIME type of the content (e.g., "image/jpeg", "application/pdf").
  optional string mime_type = 2;
  // Optional: Original filename associated with the blob.
  optional string filename = 3;
  // Optional: Character encoding if the blob represents text (e.g., "UTF-8").
  optional string encoding = 4;
  // Optional: Additional key-value metadata associated with the blob.
  map<string, string> metadata = 5;
}

// =============================================================================
// Pipeline Execution State and History
// =============================================================================

// Represents the state of a single pipeline execution run as it progresses.
// This object is managed and updated by the PipeStreamEngine.
message PipeStream {
  // REQUIRED: Unique identifier for this specific pipeline execution RUN.
  string stream_id = 1;
  // REQUIRED: Name of the pipeline DEFINITION being executed.
  string pipeline_name = 2;
  // *** NEW FIELD ***
  // The unique logical name (key from PipelineConfigDto.services map / PipeStepConfigurationDto.name)
  // that the RECIPIENT of this PipeStream should execute. Set by the SENDER.
  optional string current_pipestep_id = 3; // <<< Using your suggested name
  // The hop number incremented BEFORE the step identified by current_pipestep_id executes.
  int64 current_hop_number = 4;
  // The state of the PipeDoc.
  optional PipeDoc current_doc = 5;
  // Detailed history of steps already executed in this stream.
  repeated HistoryEntry history = 6;
  // Optional: Holds binary data.
  optional Blob input_blob = 7;
  // Optional: Context params for the whole run.
  map<string, string> context_params = 8;
}

// Records the execution details of a single step within the pipeline history.
message HistoryEntry {
  // The sequential hop number for this step execution within the stream (starts at 0).
  int64 hop_number = 1;
  // The configured name of the pipeline step that was executed.
  string step_name = 2;
  // Optional: Identifier of the specific service instance that executed the step.
  // Useful in distributed environments.
  optional string service_instance_id = 3;
  // Timestamp when the step execution began.
  google.protobuf.Timestamp start_time = 4;
  // Timestamp when the step execution ended.
  google.protobuf.Timestamp end_time = 5;
  // Execution status of the step.
  // Examples: "SUCCESS", "FAILURE", "DROPPED", "SKIPPED". REQUIRED.
  string status = 6;
  // Logs generated specifically by the processor during this step's execution.
  repeated string processor_logs = 7;
  // Detailed error information if the status is "FAILURE".
  optional ErrorData error_data = 8;
  // Optional: Richer error details using Struct, can supplement ErrorData.
  optional google.protobuf.Struct error_struct = 9;
}
